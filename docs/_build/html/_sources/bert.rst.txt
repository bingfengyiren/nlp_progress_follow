bert论文翻译
=================
原始论文地址:https://arxiv.org/pdf/1810.04805.pdf

摘要
-----------------
本论文介绍了一种称为bert的新语言模型，该模型表示来源于Transfromer的双向编码表示。不同于其它语言模型的是，bert旨在在所有层的左右上下文上通过联合概率的方式，来预训练未标记文本的深层双向表示形式。因此，仅需要调整模型的输出层就可以在许多任务中创建一个最好的模型,
